{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a75bb2e-b9d0-4a9e-83e8-cac7e362f313",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 03_tile_stats_v2.py\n",
    "from pyspark.sql import functions as F\n",
    "from trimble_geospatial_demo_utils.site_lock import acquire_site_lock, release_site_lock\n",
    "\n",
    "# ==================================================\n",
    "# Unity Catalog context\n",
    "# ==================================================\n",
    "spark.sql(\"USE CATALOG main\")\n",
    "spark.sql(\"USE SCHEMA demo\")\n",
    "\n",
    "# ==================================================\n",
    "# Read Job Parameters\n",
    "# ==================================================\n",
    "dbutils.widgets.text(\"siteId\", \"\", \"Site ID\")\n",
    "\n",
    "SITE_ID = dbutils.widgets.get(\"siteId\")\n",
    "\n",
    "# Validate required parameters\n",
    "if not SITE_ID:\n",
    "    raise ValueError(\"Missing required job parameter: siteId\")\n",
    "\n",
    "print(f\"ðŸ—ï¸  Site ID: {SITE_ID}\")\n",
    "\n",
    "# ==================================================\n",
    "# CONFIG\n",
    "# ==================================================\n",
    "INPUT_TABLE  = \"processed_points_tiled_v2\"\n",
    "OUTPUT_TABLE = \"tile_stats_v2\"\n",
    "OUTPUT_PATH  = \"abfss://aggregated@trimblegeospatialdemo.dfs.core.windows.net/tile_stats_v2\"\n",
    "\n",
    "# Water classification code (common LAS: 9). Adjust if your dataset differs.\n",
    "WATER_CLASS = 9\n",
    "\n",
    "# Threshold to consider a tile \"mostly water\"\n",
    "MOSTLY_WATER_THRESHOLD = 0.60\n",
    "\n",
    "# ==================================================\n",
    "# Job identity (for locking / audit)\n",
    "# ==================================================\n",
    "JOB_RUN_ID = spark.conf.get(\"spark.databricks.job.runId\", \"manual-notebook\")\n",
    "\n",
    "# ==================================================\n",
    "# Acquire site-level lock (latest snapshot semantics)\n",
    "# ==================================================\n",
    "acquire_site_lock(\n",
    "    spark=spark,\n",
    "    site_id=SITE_ID,\n",
    "    locked_by=JOB_RUN_ID,\n",
    "    ttl_minutes=60\n",
    ")\n",
    "\n",
    "try:\n",
    "    # ==================================================\n",
    "    # 1) Read latest processed snapshot for this site\n",
    "    # ==================================================\n",
    "    df_points = (\n",
    "        spark.table(INPUT_TABLE)\n",
    "             .filter(F.col(\"siteId\") == SITE_ID)\n",
    "    )\n",
    "\n",
    "    if df_points.rdd.isEmpty():\n",
    "        raise RuntimeError(f\"No data found for siteId={SITE_ID} in {INPUT_TABLE}\")\n",
    "\n",
    "    # ==================================================\n",
    "    # 2) Aggregate per tile (one row per tile)\n",
    "    # ==================================================\n",
    "    df_tile_stats = (\n",
    "        df_points\n",
    "        .groupBy(\"siteId\", \"tileId\")\n",
    "        .agg(\n",
    "            # Core counts\n",
    "            F.count(\"*\").alias(\"pointCount\"),\n",
    "\n",
    "            # Z stats\n",
    "            F.min(\"z\").alias(\"minZ\"),\n",
    "            F.max(\"z\").alias(\"maxZ\"),\n",
    "            F.expr(\"percentile_approx(z, 0.50)\").alias(\"z_p50\"),\n",
    "            F.expr(\"percentile_approx(z, 0.95)\").alias(\"z_p95\"),\n",
    "            F.expr(\"percentile_approx(z, 0.99)\").alias(\"z_p99\"),\n",
    "\n",
    "            # Intensity stats\n",
    "            F.expr(\"percentile_approx(intensity, 0.50)\").alias(\"intensity_p50\"),\n",
    "            F.expr(\"percentile_approx(intensity, 0.95)\").alias(\"intensity_p95\"),\n",
    "\n",
    "            # Water tracking (count of points classified as water)\n",
    "            F.sum(F.when(F.col(\"classification\") == F.lit(WATER_CLASS), F.lit(1)).otherwise(F.lit(0))).alias(\"waterPointCount\"),\n",
    "        )\n",
    "        # Water ratio derived from counts (avoid divide-by-zero)\n",
    "        .withColumn(\n",
    "            \"waterPointRatio\",\n",
    "            F.when(F.col(\"pointCount\") > 0, F.col(\"waterPointCount\") / F.col(\"pointCount\")).otherwise(F.lit(0.0))\n",
    "        )\n",
    "        # Mostly-water flag for routing\n",
    "        .withColumn(\n",
    "            \"isMostlyWater\",\n",
    "            (F.col(\"waterPointRatio\") >= F.lit(MOSTLY_WATER_THRESHOLD)).cast(\"boolean\")\n",
    "        )\n",
    "        .withColumn(\"computedAt\", F.current_timestamp())\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # 3) Safety check: ensure only one siteId\n",
    "    # ==================================================\n",
    "    if df_tile_stats.select(\"siteId\").distinct().count() != 1:\n",
    "        raise RuntimeError(\"Aggregation output contains multiple siteId values\")\n",
    "\n",
    "    # ==================================================\n",
    "    # 4) Write latest snapshot (replace entire site)\n",
    "    # ==================================================\n",
    "    (\n",
    "        df_tile_stats.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"replaceWhere\", f\"siteId = '{SITE_ID}'\")\n",
    "            .option(\"path\", OUTPUT_PATH)\n",
    "            .partitionBy(\"siteId\", \"tileId\")\n",
    "            .saveAsTable(OUTPUT_TABLE)\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # 5) Verification\n",
    "    # ==================================================\n",
    "    print(\"\\n=== Verify tile_stats_v2 ===\")\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT\n",
    "          siteId,\n",
    "          COUNT(*)                          AS tiles,\n",
    "          SUM(pointCount)                   AS totalPoints,\n",
    "          SUM(waterPointCount)              AS totalWaterPoints,\n",
    "          AVG(waterPointRatio)              AS avgWaterRatio,\n",
    "          SUM(CASE WHEN isMostlyWater THEN 1 ELSE 0 END) AS mostlyWaterTiles\n",
    "        FROM {OUTPUT_TABLE}\n",
    "        WHERE siteId = '{SITE_ID}'\n",
    "        GROUP BY siteId\n",
    "    \"\"\").show(truncate=False)\n",
    "\n",
    "    print(\"âœ… tile_stats_v2 written successfully (with water tracking)\")\n",
    "\n",
    "finally:\n",
    "    # ==================================================\n",
    "    # Release site-level lock\n",
    "    # ==================================================\n",
    "    release_site_lock(\n",
    "        spark=spark,\n",
    "        site_id=SITE_ID,\n",
    "        locked_by=JOB_RUN_ID\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_tile_stats_v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
