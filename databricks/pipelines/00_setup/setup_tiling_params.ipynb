{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ffe2da4-23ab-405b-b03a-45fcf99f28e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register control/tiling_params to Unity Catalog\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Set Unity Catalog context\n",
    "spark.sql(\"USE CATALOG main\")\n",
    "spark.sql(\"USE SCHEMA demo\")\n",
    "\n",
    "# ===== Configuration =====\n",
    "CONTROL_PATH = \"abfss://aggregated@trimblegeospatialdemo.dfs.core.windows.net/control/tiling_params\"\n",
    "CONTROL_TABLE = \"demo_control_tiling_params\"  # Unity Catalog table name\n",
    "\n",
    "print(\"=== Registering control/tiling_params to Unity Catalog ===\")\n",
    "print(f\"Source path: {CONTROL_PATH}\")\n",
    "print(f\"Target table: main.demo.{CONTROL_TABLE}\")\n",
    "\n",
    "# Check if data exists at the path\n",
    "try:\n",
    "    df = spark.read.format(\"delta\").load(CONTROL_PATH)\n",
    "    row_count = df.count()\n",
    "    print(f\"\\n✅ Data found: {row_count:,} rows\")\n",
    "    \n",
    "    # Show schema\n",
    "    print(\"\\nSchema:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Show sample data\n",
    "    print(\"\\nSample data:\")\n",
    "    df.show(10, truncate=False)\n",
    "    \n",
    "    # Register as external table in Unity Catalog\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {CONTROL_TABLE}\n",
    "        USING DELTA\n",
    "        LOCATION '{CONTROL_PATH}'\n",
    "        COMMENT 'Control table for tiling parameters'\n",
    "    \"\"\")\n",
    "    print(f\"\\n✅ Table registered in Unity Catalog: main.demo.{CONTROL_TABLE}\")\n",
    "    \n",
    "    # Verify table registration\n",
    "    print(\"\\n=== Verify table registration ===\")\n",
    "    spark.sql(f\"DESCRIBE EXTENDED {CONTROL_TABLE}\").show(50, truncate=False)\n",
    "    \n",
    "    # Query registered table\n",
    "    print(\"\\n=== Query registered table ===\")\n",
    "    result = spark.sql(f\"SELECT * FROM {CONTROL_TABLE}\")\n",
    "    print(f\"Total rows in table: {result.count():,}\")\n",
    "    result.show(10, truncate=False)\n",
    "    \n",
    "    print(\"\\n✅ Complete! Control table registered in Unity Catalog.\")\n",
    "    print(f\"   - Delta files: {CONTROL_PATH}\")\n",
    "    print(f\"   - Unity Catalog table: main.demo.{CONTROL_TABLE}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    if \"PATH_NOT_FOUND\" in str(e) or \"does not exist\" in str(e):\n",
    "        print(f\"\\n❌ Data does NOT exist at path: {CONTROL_PATH}\")\n",
    "        print(\"Please create the data first before registering the table.\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Error: {str(e)}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "setup_tiling_params",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
