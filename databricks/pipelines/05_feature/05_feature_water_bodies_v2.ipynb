{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05567160-5b07-4a16-9abf-b07529ffc68c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 05_feature_water_bodies_v2.py\n",
    "import json\n",
    "from pyspark.sql import functions as F\n",
    "from graphframes import GraphFrame\n",
    "from trimble_geospatial_demo_utils.site_lock import acquire_site_lock, release_site_lock\n",
    "from trimble_geospatial_demo_utils import send_notification\n",
    "\n",
    "# ==================================================\n",
    "# Unity Catalog context\n",
    "# ==================================================\n",
    "spark.sql(\"USE CATALOG main\")\n",
    "spark.sql(\"USE SCHEMA demo\")\n",
    "\n",
    "# ==================================================\n",
    "# Read Job Parameters\n",
    "# ==================================================\n",
    "dbutils.widgets.text(\"siteId\", \"\", \"Site ID\")\n",
    "dbutils.widgets.text(\"tileSizeM\", \"\", \"Tile Size (meters)\")\n",
    "dbutils.widgets.text(\"cellSizeM\", \"\", \"Cell Size (meters)\")\n",
    "dbutils.widgets.text(\"waterCellThreshold\", \"\", \"Water Cell Threshold\")\n",
    "dbutils.widgets.text(\"uploadJobId\", \"\", \"Upload Job ID\")\n",
    "dbutils.widgets.text(\"notificationUrl\", \"\", \"Notification URL\")\n",
    "dbutils.widgets.text(\"dbxWebhookSecret\", \"\", \"DBX Webhook Secret\")\n",
    "\n",
    "SITE_ID = dbutils.widgets.get(\"siteId\")\n",
    "TILE_SIZE_M = dbutils.widgets.get(\"tileSizeM\")\n",
    "CELL_SIZE_M = dbutils.widgets.get(\"cellSizeM\")\n",
    "WATER_CELL_THRESHOLD = dbutils.widgets.get(\"waterCellThreshold\")\n",
    "UPLOAD_JOB_ID = dbutils.widgets.get(\"uploadJobId\")\n",
    "NOTIFICATION_URL = dbutils.widgets.get(\"notificationUrl\")\n",
    "DBX_WEBHOOK_SECRET = dbutils.widgets.get(\"dbxWebhookSecret\")\n",
    "\n",
    "# Validate required parameters\n",
    "if not SITE_ID:\n",
    "    raise ValueError(\"Missing required job parameter: siteId\")\n",
    "if not TILE_SIZE_M:\n",
    "    raise ValueError(\"Missing required job parameter: tileSizeM\")\n",
    "if not CELL_SIZE_M:\n",
    "    raise ValueError(\"Missing required job parameter: cellSizeM\")\n",
    "if not WATER_CELL_THRESHOLD:\n",
    "    raise ValueError(\"Missing required job parameter: waterCellThreshold\")\n",
    "\n",
    "# Convert to appropriate types\n",
    "TILE_SIZE_M = float(TILE_SIZE_M)\n",
    "CELL_SIZE_M = float(CELL_SIZE_M)\n",
    "WATER_CELL_THRESHOLD = float(WATER_CELL_THRESHOLD)\n",
    "\n",
    "print(f\"üèóÔ∏è  Site ID: {SITE_ID}\")\n",
    "print(f\"üìè Tile Size: {TILE_SIZE_M}m\")\n",
    "print(f\"üìè Cell Size: {CELL_SIZE_M}m\")\n",
    "print(f\"üíß Water Cell Threshold: {WATER_CELL_THRESHOLD}\")\n",
    "\n",
    "# ==================================================\n",
    "# CONFIG\n",
    "# ==================================================\n",
    "CELLS_TABLE  = \"surface_cells_v2\"               # main.demo.surface_cells_v2\n",
    "OUTPUT_TABLE = \"features_water_bodies_v2\"       # main.demo.features_water_bodies_v2\n",
    "OUTPUT_PATH  = \"abfss://processed@trimblegeospatialdemo.dfs.core.windows.net/features_water_bodies_v2\"\n",
    "\n",
    "# Neighborhood type: 4-neighbour (recommended). If you want 8-neighbour later, add diagonals.\n",
    "USE_EIGHT_NEIGHBOUR = False\n",
    "\n",
    "JOB_RUN_ID = spark.conf.get(\"spark.databricks.job.runId\", \"manual-notebook\")\n",
    "\n",
    "# ==================================================\n",
    "# Set checkpoint directory for GraphFrames\n",
    "# ==================================================\n",
    "CHECKPOINT_PATH = f\"abfss://processed@trimblegeospatialdemo.dfs.core.windows.net/checkpoints/graphframes/{SITE_ID}\"\n",
    "spark.sparkContext.setCheckpointDir(CHECKPOINT_PATH)\n",
    "\n",
    "# ==================================================\n",
    "# Derived constants\n",
    "# ==================================================\n",
    "cellsPerTile = int(round(TILE_SIZE_M / CELL_SIZE_M))\n",
    "if cellsPerTile <= 0:\n",
    "    raise ValueError(\"cellsPerTile computed <= 0. Check TILE_SIZE_M and CELL_SIZE_M.\")\n",
    "\n",
    "# ==================================================\n",
    "# Acquire site lock\n",
    "# ==================================================\n",
    "acquire_site_lock(\n",
    "    spark=spark,\n",
    "    site_id=SITE_ID,\n",
    "    locked_by=JOB_RUN_ID,\n",
    "    ttl_minutes=120\n",
    ")\n",
    "\n",
    "try:\n",
    "    # ==================================================\n",
    "    # 1) Read water cells from surface_cells_v2\n",
    "    # ==================================================\n",
    "    df_cells = (\n",
    "        spark.table(CELLS_TABLE)\n",
    "             .filter(F.col(\"siteId\") == SITE_ID)\n",
    "             .filter(F.col(\"waterPointRatio\") >= F.lit(WATER_CELL_THRESHOLD))\n",
    "             .select(\n",
    "                 \"siteId\",\n",
    "                 \"tileId\",\n",
    "                 \"cellX\", \"cellY\",\n",
    "                 \"cellSizeM\",\n",
    "                 \"minZ\", \"meanZ\", \"maxZ\",\n",
    "                 \"waterPointRatio\"\n",
    "             )\n",
    "    )\n",
    "\n",
    "    if df_cells.rdd.isEmpty():\n",
    "        raise RuntimeError(f\"No water cells found for siteId={SITE_ID} with threshold={WATER_CELL_THRESHOLD}\")\n",
    "\n",
    "    # ==================================================\n",
    "    # 2) Parse tileX/tileY from tileId = \"tileX_tileY\"\n",
    "    # ==================================================\n",
    "    df_cells = (\n",
    "        df_cells\n",
    "        .withColumn(\"tileX\", F.split(F.col(\"tileId\"), \"_\").getItem(0).cast(\"int\"))\n",
    "        .withColumn(\"tileY\", F.split(F.col(\"tileId\"), \"_\").getItem(1).cast(\"int\"))\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # 3) Compute global grid coordinates so cross-tile neighbors differ by 1\n",
    "    # ==================================================\n",
    "    df_cells_global = (\n",
    "        df_cells\n",
    "        .withColumn(\"globalCellX\", F.col(\"tileX\") * F.lit(cellsPerTile) + F.col(\"cellX\"))\n",
    "        .withColumn(\"globalCellY\", F.col(\"tileY\") * F.lit(cellsPerTile) + F.col(\"cellY\"))\n",
    "        .withColumn(\"vertexId\", F.concat_ws(\"_\", F.col(\"globalCellX\"), F.col(\"globalCellY\")))\n",
    "    )\n",
    "\n",
    "    # Vertices must have column \"id\" for GraphFrames\n",
    "    vertices = df_cells_global.select(F.col(\"vertexId\").alias(\"id\")).distinct()\n",
    "\n",
    "    # ==================================================\n",
    "    # 4) Build adjacency edges efficiently (no heavy self-join)\n",
    "    # ==================================================\n",
    "    v = df_cells_global.select(\"vertexId\", \"globalCellX\", \"globalCellY\").alias(\"v\")\n",
    "\n",
    "    neighbours = [\n",
    "        F.struct((F.col(\"globalCellX\") + 1).alias(\"x\"), F.col(\"globalCellY\").alias(\"y\")),\n",
    "        F.struct((F.col(\"globalCellX\") - 1).alias(\"x\"), F.col(\"globalCellY\").alias(\"y\")),\n",
    "        F.struct(F.col(\"globalCellX\").alias(\"x\"), (F.col(\"globalCellY\") + 1).alias(\"y\")),\n",
    "        F.struct(F.col(\"globalCellX\").alias(\"x\"), (F.col(\"globalCellY\") - 1).alias(\"y\")),\n",
    "    ]\n",
    "\n",
    "    if USE_EIGHT_NEIGHBOUR:\n",
    "        neighbours += [\n",
    "            F.struct((F.col(\"globalCellX\") + 1).alias(\"x\"), (F.col(\"globalCellY\") + 1).alias(\"y\")),\n",
    "            F.struct((F.col(\"globalCellX\") + 1).alias(\"x\"), (F.col(\"globalCellY\") - 1).alias(\"y\")),\n",
    "            F.struct((F.col(\"globalCellX\") - 1).alias(\"x\"), (F.col(\"globalCellY\") + 1).alias(\"y\")),\n",
    "            F.struct((F.col(\"globalCellX\") - 1).alias(\"x\"), (F.col(\"globalCellY\") - 1).alias(\"y\")),\n",
    "        ]\n",
    "\n",
    "    nbr = (\n",
    "        df_cells_global\n",
    "        .select(\n",
    "            F.col(\"vertexId\").alias(\"src\"),\n",
    "            F.explode(F.array(*neighbours)).alias(\"nbr\")\n",
    "        )\n",
    "        .select(\n",
    "            \"src\",\n",
    "            F.col(\"nbr.x\").alias(\"nx\"),\n",
    "            F.col(\"nbr.y\").alias(\"ny\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    edges = (\n",
    "        nbr.join(v, (F.col(\"nx\") == F.col(\"v.globalCellX\")) & (F.col(\"ny\") == F.col(\"v.globalCellY\")), \"inner\")\n",
    "           .select(F.col(\"src\"), F.col(\"v.vertexId\").alias(\"dst\"))\n",
    "           .distinct()\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # 5) Connected components => waterBodyId\n",
    "    # ==================================================\n",
    "    g = GraphFrame(vertices, edges)\n",
    "    components = g.connectedComponents()  # returns: id, component\n",
    "\n",
    "    df_labeled = (\n",
    "        df_cells_global\n",
    "        .join(components, df_cells_global.vertexId == components.id, \"inner\")\n",
    "        .withColumnRenamed(\"component\", \"waterBodyId\")\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # 6) Aggregate water body features\n",
    "    # ==================================================\n",
    "    df_features = (\n",
    "        df_labeled\n",
    "        .groupBy(\"siteId\", \"waterBodyId\")\n",
    "        .agg(\n",
    "            F.count(\"*\").alias(\"cellCount\"),\n",
    "            (F.count(\"*\") * F.first(\"cellSizeM\") * F.first(\"cellSizeM\")).alias(\"areaM2\"),\n",
    "            F.min(\"minZ\").alias(\"minZ\"),\n",
    "            F.max(\"maxZ\").alias(\"maxZ\"),\n",
    "            F.avg(\"meanZ\").alias(\"meanZ\"),\n",
    "            F.min(\"globalCellX\").alias(\"bboxMinCellX\"),\n",
    "            F.min(\"globalCellY\").alias(\"bboxMinCellY\"),\n",
    "            F.max(\"globalCellX\").alias(\"bboxMaxCellX\"),\n",
    "            F.max(\"globalCellY\").alias(\"bboxMaxCellY\")\n",
    "        )\n",
    "        .withColumn(\"computedAt\", F.current_timestamp())\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # 7) Write latest snapshot by site\n",
    "    # ==================================================\n",
    "    (\n",
    "        df_features.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"replaceWhere\", f\"siteId = '{SITE_ID}'\")\n",
    "            .option(\"path\", OUTPUT_PATH)\n",
    "            .partitionBy(\"siteId\")\n",
    "            .saveAsTable(OUTPUT_TABLE)\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # 8) Quick verification\n",
    "    # ==================================================\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT\n",
    "          COUNT(*) AS waterBodies,\n",
    "          SUM(cellCount) AS totalCells,\n",
    "          SUM(areaM2) AS totalAreaM2\n",
    "        FROM {OUTPUT_TABLE}\n",
    "        WHERE siteId = '{SITE_ID}'\n",
    "    \"\"\").show(truncate=False)\n",
    "\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT\n",
    "          waterBodyId, cellCount, areaM2\n",
    "        FROM {OUTPUT_TABLE}\n",
    "        WHERE siteId = '{SITE_ID}'\n",
    "        ORDER BY areaM2 DESC\n",
    "        LIMIT 10\n",
    "    \"\"\").show(truncate=False)\n",
    "\n",
    "    print(\"‚úÖ features_water_bodies_v2 complete.\")\n",
    "except Exception as e:\n",
    "    if NOTIFICATION_URL and DBX_WEBHOOK_SECRET:\n",
    "        payload = {\n",
    "            \"runId\": spark.conf.get(\"spark.databricks.job.runId\", \"manual-notebook\"),\n",
    "            \"jobId\": UPLOAD_JOB_ID,\n",
    "            \"status\": \"FAILED\",\n",
    "            \"error\": str(e),\n",
    "            \"siteId\": SITE_ID,\n",
    "            \"tileSizeM\": str(TILE_SIZE_M),\n",
    "            \"cellSizeM\": str(CELL_SIZE_M),\n",
    "            \"waterCellThreshold\": str(WATER_CELL_THRESHOLD),\n",
    "        }\n",
    "        try:\n",
    "            send_notification(json.dumps(payload), NOTIFICATION_URL, webhook_secret=DBX_WEBHOOK_SECRET)\n",
    "        except Exception as notify_ex:\n",
    "            print(\"‚ö†Ô∏è Notification failed:\", str(notify_ex)[:200])\n",
    "    raise\n",
    "finally:\n",
    "    # Clean up checkpoint directory\n",
    "    try:\n",
    "        dbutils.fs.rm(CHECKPOINT_PATH, recurse=True)\n",
    "    except:\n",
    "        pass  # Ignore cleanup errors\n",
    "\n",
    "    release_site_lock(\n",
    "        spark=spark,\n",
    "        site_id=SITE_ID,\n",
    "        locked_by=JOB_RUN_ID\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_feature_water_bodies_v2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
